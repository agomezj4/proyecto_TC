{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import sys\n",
    "import yaml\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src/')\n",
    "project_root = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios para los archivos de parámetros y los datos\n",
    "parameters_directory = os.path.join(project_root, 'src', 'parameters')\n",
    "data_raw_directory = os.path.join(project_root, 'data', 'raw')\n",
    "data_processed_directory = os.path.join(project_root, 'data', 'processed')\n",
    "data_features_directory = os.path.join(project_root, 'data', 'featured')\n",
    "data_train_directory = os.path.join(project_root, 'data', 'model_input', 'train')\n",
    "data_val_directory = os.path.join(project_root, 'data', 'model_input', 'validation')\n",
    "data_test_directory = os.path.join(project_root, 'data', 'model_input', 'test')\n",
    "data_model_basic_directory = os.path.join(project_root, 'data', 'models', 'basic')\n",
    "data_model_ensemble_directory = os.path.join(project_root, 'data', 'models', 'ensemble')\n",
    "data_model_selection_directory = os.path.join(project_root, 'data', 'models', 'model_selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos los archivos YAML en el directorio especificado\n",
    "yaml_files = [f for f in os.listdir(parameters_directory) if f.endswith('.yml')]\n",
    "\n",
    "# Diccionario para guardar los parámetros cargados\n",
    "parameters = {}\n",
    "\n",
    "# Carga cada archivo YAML\n",
    "for yaml_file in yaml_files:\n",
    "    with open(os.path.join(parameters_directory, yaml_file), 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        key_name = f'parameters_{yaml_file.replace(\".yml\", \"\")}'\n",
    "        parameters[key_name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.processing import (validate_tags_pl, \n",
    "#                              validate_dtypes_pl, \n",
    "#                              change_names_pl, \n",
    "#                              change_dtype_pl,\n",
    "#                              delete_accents_pl,\n",
    "#                              standardize_binary_values_pl,\n",
    "#                              impute_missing_values_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_dict_path = os.path.join(data_raw_directory, parameters['parameters_catalog']['tag_dict_path'])\n",
    "# raw_data_path = os.path.join(data_raw_directory, parameters['parameters_catalog']['raw_data_path'])\n",
    "# \n",
    "# tag_dict = pl.read_excel(tag_dict_path)\n",
    "# data_raw = pl.read_csv(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba1 = validate_tags_pl(data_raw, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba2 = validate_dtypes_pl(prueba1, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba3 = change_names_pl(prueba2, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba4 = change_dtype_pl(prueba3, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba5 = delete_accents_pl(prueba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba6 = standardize_binary_values_pl(prueba5, parameters['parameters_processing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba7 = impute_missing_values_pl(prueba6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.featuring import (new_features_pl,\n",
    "#                                  add_target_variable_pl,\n",
    "#                                  one_hot_encoding_pl,\n",
    "#                                  random_forest_selection_pl,\n",
    "#                                  conditional_entropy_selection_pl,\n",
    "#                                  intersect_top_features_pl)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data_path = os.path.join(data_processed_directory, parameters['parameters_catalog']['processed_data_path'])\n",
    "#\n",
    "# data_processed = pl.read_csv(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba8 = new_features_pl(data_processed, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_directory = os.path.join(project_root, 'data', 'processed')\n",
    "# target_path = os.path.join(target_directory, parameters['parameters_catalog']['target_column_path'])\n",
    "# target = pl.read_csv(target_path)\n",
    "# prueba9 = add_target_variable_pl(prueba8, target, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba10 = one_hot_encoding_pl(prueba9, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba11 = random_forest_selection_pl(prueba10, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba12 = conditional_entropy_selection_pl(prueba10, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba13 = intersect_top_features_pl(prueba11, prueba12, prueba10, parameters['parameters_featuring'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.model_input import (min_max_scaler_pl,\n",
    "#                                    balance_target_variable_pl,\n",
    "#                                    train_test_split_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featured_data_path = os.path.join(data_features_directory, parameters['parameters_catalog']['features_data_path'])\n",
    "#\n",
    "# data_featured = pl.read_csv(featured_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba14 = min_max_scaler_pl(data_featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba15 = balance_target_variable_pl(prueba14, parameters['parameters_model_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba16 = train_test_split_pl(prueba15, parameters['parameters_model_input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.models import (train_models_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path = os.path.join(data_train_directory, parameters['parameters_catalog']['train_data_path'])\n",
    "# \n",
    "# train_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba17 = train_models_pd(train_data, parameters['parameters_models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba17['basic']['model_name'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba17['ensemble']['model_name'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nodos\n",
    "# from functions.model_selection import (optimize_train_knn, \n",
    "#                                        optimize_train_xgboost,\n",
    "#                                        ab_test_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data_path = os.path.join(data_val_directory, parameters['parameters_catalog']['validation_data_path'])\n",
    "#  \n",
    "# val_data = pd.read_parquet(val_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_path = os.path.join(data_test_directory, parameters['parameters_catalog']['test_data_path'])\n",
    "#  \n",
    "# test_data = pd.read_parquet(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict, Any, Tuple\n",
    "# def load_model(model_path: str) -> Any:\n",
    "#     with open(model_path, 'rb') as f:\n",
    "#         return pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_model_path = os.path.join(data_model_basic_directory, parameters['parameters_catalog']['basic_model_path'])\n",
    "# basic_model = load_model(basic_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_model_path = os.path.join(data_model_ensemble_directory, parameters['parameters_catalog']['ensemble_model_path'])\n",
    "# ensemble_model = load_model(ensemble_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba18 = optimize_train_knn(basic_model,\n",
    "#                              val_data,\n",
    "#                              test_data,\n",
    "#                              parameters['parameters_model_selection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba19 = optimize_train_xgboost(ensemble_model,\n",
    "#                              val_data,\n",
    "#                              test_data,\n",
    "#                              parameters['parameters_model_selection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba20 = ab_test_models(prueba18,\n",
    "#                              prueba19,\n",
    "#                              test_data,\n",
    "#                              parameters['parameters_model_selection'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11 proyecto_tc",
   "language": "python",
   "name": "proyecto_tc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
